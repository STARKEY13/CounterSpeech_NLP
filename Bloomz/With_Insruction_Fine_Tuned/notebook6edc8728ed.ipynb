{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11488033,"sourceType":"datasetVersion","datasetId":7200788},{"sourceId":11488038,"sourceType":"datasetVersion","datasetId":7200792},{"sourceId":11488144,"sourceType":"datasetVersion","datasetId":7200876}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets evaluate bert_score detoxify","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:23:46.640135Z","iopub.execute_input":"2025-05-08T10:23:46.640686Z","iopub.status.idle":"2025-05-08T10:23:50.127438Z","shell.execute_reply.started":"2025-05-08T10:23:46.640664Z","shell.execute_reply":"2025-05-08T10:23:50.126653Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom datasets import load_dataset, DatasetDict\nimport numpy as np\nfrom evaluate import load\n\n# 1. Load and prepare dataset\ndataset = load_dataset(\"Rhma/DIALOCONAN\")\nsmall_dataset = dataset[\"train\"].select(range(3500))\n\n# Split train data into train/validation\ntrain_val = small_dataset.train_test_split(test_size=0.15, seed=42)\ndataset = DatasetDict({\n    \"train\": train_val[\"train\"],\n    \"validation\": train_val[\"test\"]\n})\n\n# 2. Group turns by dialogue_id\ndef group_dialogues(examples):\n    sorted_data = sorted(zip(examples[\"dialogue_id\"], \n                            examples[\"turn_id\"], \n                            examples[\"text\"],\n                            examples[\"type\"],\n                            examples[\"TARGET\"]),\n                       key=lambda x: (x[0], x[1]))\n    dialogues = []\n    current_dialogue = []\n    current_id = None\n    for item in sorted_data:\n        dialogue_id, turn_id, text, turn_type, target = item\n        if dialogue_id != current_id:\n            if current_id is not None and current_dialogue:\n                dialogues.append({\n                    \"dialogue_id\": current_id,\n                    \"turns\": current_dialogue,\n                    \"target\": current_dialogue[0][\"target\"]\n                })\n            current_id = dialogue_id\n            current_dialogue = []\n        current_dialogue.append({\n            \"text\": text,\n            \"type\": turn_type,\n            \"target\": target\n        })\n    if current_id is not None and current_dialogue:\n        dialogues.append({\n            \"dialogue_id\": current_id,\n            \"turns\": current_dialogue,\n            \"target\": current_dialogue[0][\"target\"]\n        })\n    return {\"dialogues\": dialogues}\n\nprocessed_dataset = dataset.map(\n    group_dialogues,\n    batched=True,\n    remove_columns=dataset[\"train\"].column_names,\n    batch_size=1000\n)\n\n# 3. Create conversation history for each CN turn\ndef create_conversation_history(examples):\n    new_examples = {\"input\": [], \"target\": []}\n    for dialogue in examples[\"dialogues\"]:\n        history = []\n        for turn in dialogue[\"turns\"]:\n            if turn[\"type\"] == \"CN\":\n                new_examples[\"input\"].append(\" [SEP] \".join(history))\n                new_examples[\"target\"].append(turn[\"text\"])\n            history.append(turn[\"text\"])\n    return new_examples\n\nfinal_dataset = processed_dataset.map(\n    create_conversation_history,\n    batched=True,\n    remove_columns=[\"dialogues\"]\n)\n\n# 4. Load pretrained BLOOMZ model and tokenizer\nmodel_name = \"bigscience/bloomz-3b\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n\n# 5. Generation function (inference only)\ndef generate_counterspeech(dialogue_history):\n    device = model.device\n    input_text = \" [SEP] \".join(dialogue_history) + \" [ANS] \"\n    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n    with torch.inference_mode():\n        outputs = model.generate(\n            inputs.input_ids,\n            max_new_tokens=128,\n            num_beams=5,\n            repetition_penalty=2.0,\n            early_stopping=True\n        )\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# 6. Example usage\nsample_dialogue = [\n    \"You people are ruining our country!\",\n    \"Immigrants are stealing our jobs!\",\n    \"We should send them all back!\"\n]\nprint(\"\\nGenerated counterspeech:\")\nprint(generate_counterspeech(sample_dialogue))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**with instruction tuning**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\nfrom datasets import load_dataset, DatasetDict\nfrom peft import LoraConfig, get_peft_model, TaskType\nimport numpy as np\nfrom evaluate import load\n\n# 1. Load and prepare dataset\ndataset = load_dataset(\"Rhma/DIALOCONAN\")\nsmall_dataset = dataset[\"train\"].select(range(3500))\ntrain_val = small_dataset.train_test_split(test_size=0.15, seed=42)\ndataset = DatasetDict({\n    \"train\": train_val[\"train\"],\n    \"validation\": train_val[\"test\"]\n})\n\n# 2. Group turns by dialogue_id\ndef group_dialogues(examples):\n    sorted_data = sorted(zip(examples[\"dialogue_id\"], \n                            examples[\"turn_id\"], \n                            examples[\"text\"],\n                            examples[\"type\"],\n                            examples[\"TARGET\"]),\n                       key=lambda x: (x[0], x[1]))\n    dialogues = []\n    current_dialogue = []\n    current_id = None\n    for item in sorted_data:\n        dialogue_id, turn_id, text, turn_type, target = item\n        if dialogue_id != current_id:\n            if current_id is not None and current_dialogue:\n                dialogues.append({\n                    \"dialogue_id\": current_id,\n                    \"turns\": current_dialogue,\n                    \"target\": current_dialogue[0][\"target\"]\n                })\n            current_id = dialogue_id\n            current_dialogue = []\n        current_dialogue.append({\n            \"text\": text,\n            \"type\": turn_type,\n            \"target\": target\n        })\n    if current_id is not None and current_dialogue:\n        dialogues.append({\n            \"dialogue_id\": current_id,\n            \"turns\": current_dialogue,\n            \"target\": current_dialogue[0][\"target\"]\n        })\n    return {\"dialogues\": dialogues}\n\nprocessed_dataset = dataset.map(\n    group_dialogues,\n    batched=True,\n    remove_columns=dataset[\"train\"].column_names,\n    batch_size=1000\n)\n\n# 3. Create conversation history for each CN turn\ndef create_conversation_history(examples):\n    new_examples = {\"input\": [], \"target\": []}\n    for dialogue in examples[\"dialogues\"]:\n        history = []\n        for turn in dialogue[\"turns\"]:\n            if turn[\"type\"] == \"CN\":\n                new_examples[\"input\"].append(\" [SEP] \".join(history))\n                new_examples[\"target\"].append(turn[\"text\"])\n            history.append(turn[\"text\"])\n    return new_examples\n\nfinal_dataset = processed_dataset.map(\n    create_conversation_history,\n    batched=True,\n    remove_columns=[\"dialogues\"]\n)\n\n# 4. Instruction tuning formatting\ndef format_instruction(examples):\n    inputs = []\n    targets = []\n    for inp, tgt in zip(examples[\"input\"], examples[\"target\"]):\n        instruction = (\n            \"[INST] <<SYS>>\\n\"\n            \"You are a helpful assistant that generates fact-based counterspeech.\"\n            \"<<SYS>>\\n\"\n            f\"{inp} [/INST]\"\n        )\n        inputs.append(instruction)\n        targets.append(tgt)\n    return {\"input\": inputs, \"target\": targets}\n\ninstruction_dataset = final_dataset.map(\n    format_instruction,\n    batched=True,\n    remove_columns=[\"input\", \"target\"]\n)\n\n# 5. Tokenization\nmodel_name = \"bigscience/bloomz-3b\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token\n\ndef preprocess_function(examples):\n    inputs = [inp + \" \" + tgt for inp, tgt in zip(examples[\"input\"], examples[\"target\"])]\n    model_inputs = tokenizer(\n        inputs,\n        max_length=128,\n        truncation=True,\n        padding=\"max_length\"\n    )\n    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n    return model_inputs\n\ntokenized_datasets = instruction_dataset.map(\n    preprocess_function,\n    batched=True,\n    remove_columns=[\"input\", \"target\"]\n)\n\n# 6. LoRA\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"query_key_value\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM,\n)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n\n# 7. TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir=\"./bloomz-lora-instruction\",\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    num_train_epochs=2,\n    fp16=True,\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    save_strategy=\"steps\",\n    save_steps=500,\n    logging_strategy=\"steps\",\n    logging_steps=10,\n    report_to=\"none\",\n    eval_accumulation_steps=1,\n    learning_rate=2e-4\n)\n\n\n# 9. Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer\n    \n)\n\nprint(\"Starting instruction tuning training...\")\ntrainer.train()\n\n# 10. Generation function (for inference)\ndef generate_counterspeech(dialogue_history):\n    device = model.device\n    input_text = \"[INST] <<SYS>>\\nYou are a helpful assistant that generates fact-based counterspeech.<<SYS>>\\n\" + \" [SEP] \".join(dialogue_history) + \" [/INST] \"\n    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n    with torch.inference_mode():\n        outputs = model.generate(\n            inputs.input_ids,\n            max_new_tokens=128,\n            num_beams=5,\n            repetition_penalty=2.0,\n            early_stopping=True\n        )\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Example usage\nsample_dialogue = [\n    \"You people are ruining our country!\",\n    \"Immigrants are stealing our jobs!\",\n    \"We should send them all back!\"\n]\nprint(\"\\nGenerated counterspeech after fine-tuning:\")\nprint(generate_counterspeech(sample_dialogue))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:27:29.050381Z","iopub.execute_input":"2025-05-08T10:27:29.050978Z","iopub.status.idle":"2025-05-08T10:45:18.802048Z","shell.execute_reply.started":"2025-05-08T10:27:29.050955Z","shell.execute_reply":"2025-05-08T10:45:18.801310Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_123/826207108.py:153: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 4,915,200 || all params: 3,007,472,640 || trainable%: 0.1634\nStarting instruction tuning training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2978' max='2978' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2978/2978 17:40, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.055100</td>\n      <td>0.887513</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.932000</td>\n      <td>0.876457</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.668300</td>\n      <td>0.860788</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.184300</td>\n      <td>0.866063</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.544900</td>\n      <td>0.865661</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nGenerated counterspeech after fine-tuning:\n[INST] <<SYS>>\nYou are a helpful assistant that generates fact-based counterspeech.<<SYS>>\nYou people are ruining our country! [SEP] Immigrants are stealing our jobs! [SEP] We should send them all back! [/INST]  What do you mean by 'ruining our country'? Do you have any facts to back up your statement?\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Install dependencies if not already installed\n!pip install -q evaluate detoxify tqdm\n!pip install rouge_score bert_score\nfrom evaluate import load\nfrom detoxify import Detoxify\nfrom tqdm import tqdm\nimport numpy as np\nimport math\n\n# Load metrics\nrouge = load(\"rouge\")\nbertscore = load(\"bertscore\")\n# Use first 100 samples\ninputs = [ex[\"input\"] for ex in final_dataset[\"validation\"]][:100]\ntargets = [ex[\"target\"] for ex in final_dataset[\"validation\"]][:100]\n\n# Generate predictions\nprint(\"Generating counter speech...\")\ngenerated = []\nfor text in tqdm(inputs, desc=\"Generating\"):\n    response = generate_counterspeech(text)  # <-- make sure this function is defined\n    generated.append(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:45:39.731278Z","iopub.execute_input":"2025-05-08T10:45:39.731588Z","iopub.status.idle":"2025-05-08T10:52:56.325007Z","shell.execute_reply.started":"2025-05-08T10:45:39.731564Z","shell.execute_reply":"2025-05-08T10:52:56.324210Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: bert_score in /usr/local/lib/python3.11/dist-packages (0.3.13)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.5.1+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.51.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.30.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=a139525f55853e0bf5d8314e3aaebdfc9b4bc27b750a107cd363c34ba28f8be3\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e1d0874584f46e0ab4c2013bcf6e192"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f78bd1970f13459ea34200b4fc7ff87e"}},"metadata":{}},{"name":"stdout","text":"Generating counter speech...\n","output_type":"stream"},{"name":"stderr","text":"Generating: 100%|██████████| 100/100 [07:05<00:00,  4.26s/it]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# BERTScore\nprint(\"Calculating BERTScore...\")\nbertscore_result = bertscore.compute(\n    predictions=generated,\n    references=targets,\n    model_type=\"distilbert-base-uncased\"\n)\nprint(f\"BERTScore F1: {np.mean(bertscore_result['f1']):.4f}\")\n\n# ROUGE\n# ROUGE\nprint(\"Calculating ROUGE...\")\nrouge_result = rouge.compute(predictions=generated, references=targets)\nprint(f\"ROUGE-1 F1: {rouge_result['rouge1']:.4f}\")\nprint(f\"ROUGE-2 F1: {rouge_result['rouge2']:.4f}\")\nprint(f\"ROUGE-L F1: {rouge_result['rougeL']:.4f}\")\n# Perplexity\nprint(\"Calculating Perplexity...\")\ndef calculate_perplexity(texts):\n    total_log_prob = 0.0\n    total_words = 0\n    for text in texts:\n        words = text.split()\n        total_words += len(words)\n        # You can use a pre-trained language model (e.g., GPT-2) for calculating perplexity\n        # Here, we will use a placeholder for the log-prob calculation, which should ideally come from a language model\n        # For simplicity, assume a fixed value here\n        total_log_prob += len(words) * math.log(1.0)  # Placeholder for log-prob calculation\n    return math.exp(-total_log_prob / total_words) if total_words > 0 else float('inf')\n\nperplexity_result = calculate_perplexity(generated)\nprint(f\"Perplexity: {perplexity_result:.4f}\")\n\n# Toxicity\nprint(\"Calculating Toxicity...\")\ntoxicity_scores = [Detoxify('original').predict(pred)['toxicity'] for pred in tqdm(generated, desc=\"Toxicity\")]\navg_toxicity = np.mean(toxicity_scores)\nprint(f\"Avg. Toxicity Score: {avg_toxicity:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:53:22.227648Z","iopub.execute_input":"2025-05-08T10:53:22.227996Z","iopub.status.idle":"2025-05-08T10:54:35.441639Z","shell.execute_reply.started":"2025-05-08T10:53:22.227955Z","shell.execute_reply":"2025-05-08T10:54:35.440518Z"}},"outputs":[{"name":"stdout","text":"Calculating BERTScore...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0087f4bdd484ef3993dcea0ca59537e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"965cbc76303c4b49aae9080086ab55fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f2fc874f09b4f68873547995f53e4d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04af8102020c4fb9b3474d94355b8f4a"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c93e6d9c85f4a12869b62ab84c8a2d6"}},"metadata":{}},{"name":"stdout","text":"BERTScore F1: 0.6740\nCalculating ROUGE...\nROUGE-1 F1: 0.1198\nROUGE-2 F1: 0.0059\nROUGE-L F1: 0.0828\nCalculating Perplexity...\nPerplexity: 1.0000\nCalculating Toxicity...\n","output_type":"stream"},{"name":"stderr","text":"Toxicity:   0%|          | 0/100 [00:00<?, ?it/s]Downloading: \"https://github.com/unitaryai/detoxify/releases/download/v0.1-alpha/toxic_original-c1212f89.ckpt\" to /root/.cache/torch/hub/checkpoints/toxic_original-c1212f89.ckpt\n\n  0%|          | 0.00/418M [00:00<?, ?B/s]\u001b[A\n  2%|▏         | 10.1M/418M [00:00<00:05, 83.6MB/s]\u001b[A\n  5%|▍         | 20.1M/418M [00:00<00:04, 89.6MB/s]\u001b[A\n  7%|▋         | 30.1M/418M [00:00<00:04, 85.8MB/s]\u001b[A\n 10%|▉         | 40.1M/418M [00:00<00:04, 87.4MB/s]\u001b[A\n 12%|█▏        | 48.5M/418M [00:00<00:06, 56.5MB/s]\u001b[A\n 13%|█▎        | 55.0M/418M [00:00<00:06, 55.5MB/s]\u001b[A\n 15%|█▍        | 62.2M/418M [00:00<00:06, 60.3MB/s]\u001b[A\n 17%|█▋        | 70.1M/418M [00:01<00:05, 65.4MB/s]\u001b[A\n 19%|█▉        | 80.1M/418M [00:01<00:04, 72.1MB/s]\u001b[A\n 22%|██▏       | 90.1M/418M [00:01<00:04, 74.3MB/s]\u001b[A\n 24%|██▍       | 100M/418M [00:01<00:04, 76.5MB/s] \u001b[A\n 26%|██▋       | 110M/418M [00:01<00:03, 82.6MB/s]\u001b[A\n 29%|██▉       | 120M/418M [00:01<00:03, 86.6MB/s]\u001b[A\n 31%|███       | 130M/418M [00:01<00:03, 86.6MB/s]\u001b[A\n 34%|███▎      | 140M/418M [00:01<00:03, 88.8MB/s]\u001b[A\n 36%|███▌      | 150M/418M [00:02<00:03, 86.2MB/s]\u001b[A\n 38%|███▊      | 160M/418M [00:02<00:02, 90.2MB/s]\u001b[A\n 41%|████      | 170M/418M [00:02<00:02, 90.4MB/s]\u001b[A\n 43%|████▎     | 180M/418M [00:02<00:02, 84.7MB/s]\u001b[A\n 46%|████▌     | 190M/418M [00:02<00:02, 88.3MB/s]\u001b[A\n 48%|████▊     | 200M/418M [00:02<00:02, 88.0MB/s]\u001b[A\n 50%|█████     | 210M/418M [00:02<00:02, 91.7MB/s]\u001b[A\n 53%|█████▎    | 220M/418M [00:02<00:02, 93.4MB/s]\u001b[A\n 55%|█████▌    | 230M/418M [00:02<00:02, 94.5MB/s]\u001b[A\n 57%|█████▋    | 240M/418M [00:03<00:01, 94.5MB/s]\u001b[A\n 60%|█████▉    | 250M/418M [00:03<00:01, 91.5MB/s]\u001b[A\n 62%|██████▏   | 260M/418M [00:03<00:01, 93.9MB/s]\u001b[A\n 65%|██████▍   | 270M/418M [00:03<00:01, 94.1MB/s]\u001b[A\n 67%|██████▋   | 280M/418M [00:03<00:01, 88.5MB/s]\u001b[A\n 69%|██████▉   | 290M/418M [00:03<00:01, 91.5MB/s]\u001b[A\n 72%|███████▏  | 300M/418M [00:03<00:01, 93.0MB/s]\u001b[A\n 74%|███████▍  | 310M/418M [00:03<00:01, 96.1MB/s]\u001b[A\n 77%|███████▋  | 320M/418M [00:03<00:01, 95.9MB/s]\u001b[A\n 79%|███████▉  | 330M/418M [00:04<00:00, 95.8MB/s]\u001b[A\n 81%|████████▏ | 340M/418M [00:04<00:00, 95.1MB/s]\u001b[A\n 84%|████████▍ | 350M/418M [00:04<00:00, 93.9MB/s]\u001b[A\n 86%|████████▌ | 360M/418M [00:04<00:00, 94.6MB/s]\u001b[A\n 89%|████████▊ | 370M/418M [00:04<00:00, 96.7MB/s]\u001b[A\n 91%|█████████ | 380M/418M [00:04<00:00, 95.2MB/s]\u001b[A\n 93%|█████████▎| 390M/418M [00:04<00:00, 96.0MB/s]\u001b[A\n 96%|█████████▌| 400M/418M [00:04<00:00, 92.9MB/s]\u001b[A\n100%|██████████| 418M/418M [00:04<00:00, 87.9MB/s]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eabfcf301d684bf5bf310da954059ca1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"060a1550de854093a72670b5a8b3e997"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33c7cc3d3a7847e6bc8d8f8a35ff2a5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1e75a347d034208896902ca3a45fdc9"}},"metadata":{}},{"name":"stderr","text":"Toxicity: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Avg. Toxicity Score: 0.0122\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5}]}